I have done an introduction to Artificial Intelligence (AI) course and I want to share my learning experience. This post covers my notes and summaries of the content of the course.

HISTORY
On the early sixties, there was a gathering between several investigators interested on artificial intelligence, neural networks and automats theory as a consequence of the first works made on the field.

The following years there was a lot of progress on the field and several programs were design to solve numerous problems:

Geometric problems
Algebraic problems
Checkers players
LISP programming language was invented
These programs were successful on limited domains, known as micro-worlds, but failed on the adaptation to real environments because of the following three factors:

Lack of knowledge on the application domain consistent only on a few syntactic manipulations.
Most of the problem had NP complexity class . With low input knowledge, the problems could be solved, but with bigger input data, they were unsolvable.
The basic structures used to generate an intelligent conduct, had big limitations. The neuronal network couldn’t learn the XOR function.
The problem resolution was based on a general purpose search engine with high cost. To lower that cost, the first search algorithms were developed, like Heuristic Search and Alpha Beta Search. Some kind of logic was starting to be developed to represent the knowledge domain of the application.

Other works were focused on add some kind of learning process to the applications:

The ID3 decision tree was created
Version space learning
Backpropagation
Concepts like uncertainty and non precision started to be taken into account. With all those development, at the eighties, the first commercial systems where launched.

DEFINITIONS AND POINTS OF VIEW
There is not a single definition of AI but a lot of them according different points of view. We are going to consider AI as a computer science field and how the different programs and applications define it.

The goals of the different programs will lead to different definitions:

The goal of the program can be obtain an specific conduct or to obtain an specific reasoning. This conduct/reasoning pair makes the first dimension.
On the other hand, it is required that the programs are correct. You can measure this correction comparing the performance with the performance on actual people or compared against an ideal concept of intelligence. This ideal is named rationality. The way we measure the correction is the second dimension.
Using these two dimensions, there are four possible visions for the goals and so, four possible definitions:

Act like people: The Turing test. This definition is based on the proposal by Alan Turing defining intelligence as an operational way: A conduct is intelligence when has enough level to confuse a human interlocutor.
Reason like people: The cognitive model. In this definition, not only the result is important but also how it is obtained. The goal is for the process to be similar to the one made by humans. The General Problem Solver.
Reason rationally: The thoughts laws. This point of view is based on considering what it means to think correctly or, what is equivalent, know when a new fact can be deduced logically from the knowledge of what is available.
Act rationally: The rational agent. What it is important is to reach the correct conclusions, not if the conclusions were obtained using logic deductions.
Considering the follow hypothesis:

The physical symbol system hypothesis
Heuristic search hypothesis
We can achieve intelligent activity with the use of:

Symbols: The meaningful elements of a system.
Operations: Operations between the symbols allowing us to generate solutions.
Search: To select a solution from the possible ones generated from the operations.
This hypothesis explains the two most important elements on the development of AI applications:

Define the symbolic structures and operations to solve problems.
Define search strategies to find the potential solutions generated by these structures and operations.
THREE ALTERNATIVES
This definition is challenged by other authors and other systems had been build following different hypothesis. These are based on different hypothesis:

Biologic models based systems:

This alternative is based on neuronal networks. These networks represent the world thought the weight associated to each connection (or neuron), no symbols required.

Emergent systems:

The solution to a problem is not obtained from a single individual system but emerges from the activities of independent agents (and relatively simple though usually specialists).

Situated action theory:

The theories of the action argue that intelligence should not be seen as a process of building and evaluating models of the world, but rather as a less structured process of acting in the world and responding to results obtained. Therefore, more importance is given to the ability to act than when explaining these actions.

SOME APPLICATIONS
Theorist (Newell, Shaw, Simon, 1957): An automatic theorem prover.

Mycin (Shortliffe i Buchanan, 1975): Designed to help on the recommendations of therapies fitted for a patients with bacterial infections.

AM (Lenat, 1977): Experimental program to build theories on the mathematics field. From a group of arithmetic concepts, the software builds new concepts.

Prospector (Duda, 1979): Helps locate minerals like copper and uranium. It was a huge success at the eighties when it recommended the excavation on a place where a large deposit of molybdenum was found.

EQP (McCune, 1997): The EQP system proved the robbing problem. It is a well known problem on boolean algebraic unsolved until then.

Deep Blue (IBM, 1997): The first computer that won a human on chess. It won the world champion G. Kasparov. The program has knowledge of the domain included on the function used to evaluate the different games. Also, it included a large database with final-game data that allowed it to play a perfect game once achieved that stage.

CHARACTERISTICS
There are a lot of intelligent systems applied to several different environments but there are some commons elements on all of them:

Use of symbolic information: The information to process is symbolic. They have to reason about facts, abstract concepts and obtain conclusions.
Use of domain description: In order to find a solution, the systems have to know the problem environment.
Use of incomplete, inaccurate or conflict data: There is some level of uncertainty with the data to be processed.
Use heuristic methods: On the AI applications, we implement how to find the solution instead of a list of steps to follow. The heuristic methods, help to do that but don’t grant success. Most of the times, there isn’t a better solution, but they can found a good one enough to keep going.
Are adaptive: When the environment changes, the system has to be able to change it’s behaviour.
PROBLEM SOLVING AND SEARCH
We have stablished that intelligent activity is reached thought the use of symbols to represent the problem domain, operations over this patterns and search to select a solution from the possibilities.

At that point, we can see how to formulate a problem defining the state space.

STATE SPACE AND PROBLEM REPRESENTATION
We have to create a model of the problem. This process will usually follow the steps:

Environment modeling We define an STATE as the world representation in a specific state. We have to deduce on our system…
What is an state?
What are the possible states?
How do we represent an state?
Actions modeling We call ACTIONS as the way to move from an state to another and the BRANCHING FACTOR as the number of actions that can be applied on an specific state. Then we can define the STATE SPACE which is the group of possible states and the group of actions.
Here an STATE SPACE representation for the linear jigsaw puzzle problem:

Module layout

Problem definition We can define the problem as the initial state and the goal function.
BUILDING A SOLUTION
We define the solution as the road through the space state graph where, given an initial state, it will satisfy the goal function.

The search algorithm chooses a node and consider the possible actions that can be applied. Each one of this actions creates a new steps group. This made the representation of the data structure as a tree, a searching tree.

Tree layout

For the implementation we need the data structure for the tree and the functions for build and operate with the tree, that will define the following steps:

Node Representation

A node will contain:

id
parent id
how is generated
state
additional info
Data Structure

Already expanded nodes (List)
Nodes to expand (Queue with priority)
Apply selection operation
Add nodes to the structure
Algorithm

Tree layout

NOT INFORMED SEARCH STRATEGIES
The search strategy is defined by the following questions:

Which node we have to expand?
How to sort the not-expanded nodes?
Amplitude search
Amplitude search

Deep search
Deep search

Uniform Cost search The uniform cost search introduces the concept of the cost of it’s path from the initial state. We call that g(h). This search is complete and optimal when that cost function is always positive.
We can consider the uniform cost search as a generalisation of the amplitude search when the cost of all operators are the same.

HEURISTIC SEARCHES
In general, we can not know how close is a state from the solution. We will use a function that give us an estimation from the node to the solution. That is called heuristic function.

An heuristic function is a function that applied to a node, estimates the cost of the best path between that node and a solution node. This function are represented as h(n)

Avid Search The uniform cost search consider the cost only from the initial state. It does not take into consideration that the next node has to lead to a solution. Using an heuristic function h(n) as a criterion to order the nodes on the ready to expand list, defines the avid search.
A* Algorithm The avid search uses an heuristic function to estimate the node that correspond to the minimum cost from a node to the goal node. That choosing thought, makes the search not optimal nor complete. On the other hand, the uniform cost search minimises the cost of the path to origin node to current node.
The two algorithms are complementary, we can define a function:

f(n) = g(n) + h(n)

Where:

g(n) is the cost from the initial state to n
h(n) is the estimation from this node to the solution
We can establish that f(n) is an estimation of the cost of the path going from an initial state to another state solution going through the current node n

The selection of the node to expand according to this function is what it is called algorithm A*:

Amplitude search

The completion and optimality of the algorithm A* depends on the heuristic function. An algorithm A* is optimal and complete when the heuristic function does not over-estimate the cost to reach the goal. If the heuristic function covers that case, it is an admissible heuristic function.

This is a representation of the A* algorithm on pseudo-code:

begin
    input the start node S and the set of GOALS of goal nodes;
    OPEN <- {S}
    G[S] <- 0;
    PRED[S] <- null;
    found <- false;

    while OPEN is not empty and found is false do
        begin
            L <- the set of nodes OPEN for which F is the least;

            if L is a singleton then let X be its sole element
            else if there are any goal nodes in L
                then let X be one of them;
                else let X be any element of L;

            remove X from OPEN and put X into CLOSED;

            if X is a goal node then found <- true
                else begin
                    generate the set SUCCESSORS of successors of X;
                    for each Y in SUCCESSORS do
                        if Y is not already on OPEN or on CLOSED then
                            begin
                                G[Y] <- G[X] + distance(X,Y);
                                F[Y] <- G[Y] + h(Y);
                                PRED[Y] <- X;
                                insert Y on OPEN;
                            end
                        else
                            begin
                                Z <- PRED[Y];
                                temp <- F[Y]-G[Z] - distance(Z,Y) + G[X] + distance(X,Y);
                                if temp < F[Y] then
                                    begin
                                        G[Y] <- G[Y] - F[Y] + temp;
                                        F[Y] <- temp;
                                        PRED[Y] <- X;
                                        if Y is on CLOSED then
                                            insert Y on OPEN and remove Y from CLOSED;
                                    end;
                            end;
                end;
        end;

    if found is false then output "Failure";
    else trace the pointers in the PRED fields from X back to S, "CONSing" each node onto the growing list of nodes to get the path from S to X;
end;
KNOWLEDGE SYSTEMS
The knowledge system solve the problems using an intense knowledge of the application field. The knowledge base, the inference system and the user interface are the components associated.

Building that kind of a system requires a big investment in time and resources and it has to be carefully evaluated if it is worth it.

You should only build a knowledge system when:

The usual programming techniques can not solve the problem.
There are experts that have a good structured knowledge of the system domain.
We don´t always have human experience on the environments where the knowledge is needed.
If there is a point to build a knowledge system, then you have to build a model.

A model is an abstraction used for specific goals. When we know the model goal, we can do an approximation of the phenomena we want to model. It represents a structured way to understand the entities and the processes that allows to build the solution on the real world. The model allows has to understand better the process and also be able to predict.

SYSTEMS BASED ON RULES
These systems are used mostly to solve problems of classification and diagnose. There are based on facts and rules

Facts: Knowledge about the objects of the system.
Rules: Establish the relation between the objects.
Follow this format: IF [premise] THEN [conclusion] where both premise and conclusion are assertions of the facts.
Using the facts and rules, the inference system extract conclusions about the knowledge base which can be concluding new facts or assert the certainty of a fact.

Rule system architecture

Rule system architecture

Rules base: First formal aspect of the representation. It contains de group of rules, the info of the domain.
Working memory: Second formal aspect of the representation. It contains the group of facts which are temporary and relative to the specific problem trying to solve.
Interpret: It is the inference aspect, it concludes new facts.
About the cyclic system of inference:

Inference

Recovery: Selects the rules that we can apply. The selected sub group is named conflict set.
Refinement: Selects a rule from the sub group.
Execution: Applies the rule.
The cycle ends once it has been proven whatever it is we are trying to prove or the conflict set is empty. So, we have a goal (a solution state) and a search problem (the group of rules). We can apply the search strategies explained before.

Strategies for drive the search

Textual order
Refractoriness
Recency
Specificity
Strategies for doing the inference

Forward reasoning
We start from the knowledge and start applying the rules until the goal is reached. To know if we can apply a rule, we look to the precedent. If it is fulfilled, it is added to the work memory the rule conclusions.

Backward reasoning
We start from the goal and select the rules that fulfill the goal.

SYSTEMS WITH STRUCTURED REPRESENTATION
The structured representation allows to relate the units from which the knowledge is defined. This is accomplished modeling the interconnections between the objects of the domain. Some of this representations are:

Frames
Semantic networks
Scripts
The difference between them is blurry since their structure is similar: several concepts and relations between them. Using Frames as an example, it can represent concepts defining the situation and domain of the problem. It can take into account the typical values, the exceptions and the incomplete or redundant information. It also allows modifications, inclusions or suppressions of their properties, creating a frame restructure.

FORMAL ASPECTS
From the formal point of view, a frame system is a network where each node represents an object, and the arcs mean the relations that can be establish between the objects. This representation structures the knowledge in a similar way than the object oriented programming paradigm.

As so, the relation between the objects are the same of the OOP like:

Class
Sub Class
Super Class
Instance
Inherence
Frame example

There to fields types: member slot and own slot. Each instance of the class has a copy of the member slot and can be modified and the own slot are belong to the frame, so each instances share them. Some of the elements typically included on the fields are:

Values of the domain
Reference to another frame, the value indicates an object of the same system. Like on the example above, we have Maria as the owner of the frame car.
Value restrictions
Functions: The frame as a function associated that it is called every time there is a need of calculate the field.
Demons: Procedures called as secondary effect of a relevant action on the knowledge base.
INFERENTIAL ASPECTS
When asking to a frame representation, the problem normally is to know if an object satisfies some property or to know the value that an specific field associates with the object. For doing that, the frame system uses inherence to find the field which is solution to the problem.

It can be a problem when there is multiple inherence (which happens most of the time). Depending of the order on which the relations are considered, the system will answer one thing or another. So, the multiple inherence is a search problem because to find a result, we have to consider different alternatives and not all of them lead to a solution.
In abstraction, the problem of finding the solution field is search on a graph since we find a node which satisfies the property. As so, we can use all the search strategies explained before.

The algorithms must take into account the intersections where there are several paths: before considering what is in the object associated to the intersection, the nodes in the paths that carry it must have been taken into account from the origin.

To solve that problem, we can use the topological sorting algorithm.

CASE BASED SYSTEMS
The case based reasoning is formed on the idea of using previous experiences and solve new situations in a similar way that we solved the previous ones.

There is a Case Data Base storing pass experiences in form of cases. Each case is composed by a situation and a solution. In order to solve the new situation, you try to adapt an old solution to the new problem. This kind of systems are suited for problems involving design, diagnose and planning. The definition is not made by rules or frameworks but by operations.

INFERENTIAL ASPECTS
The inferential is composed by four steps:

Retrieval
Reuse
Revision
Retain
Inferential Aspect Case Based

MODEL BASED SYSTEMS INFERENTIAL ASPECTS
The model based systems knowledge is based on cause/effect relations.

A model-based diagnostics system must find the set of failures most likely to explain the behaviour that is observed in the system. To do so, it raises different alternatives and rejects those that do not match with the model and maintain those that are corroborated by the model.

FUZZY LOGIC SYSTEMS
Based on rules defined on fuzzy groups terms. Considering the rule system that we know:

IF [premise] THEN [conclusion] now both premise and conclusion are fuzzy groups.

Fuzzy Groups:

CERTAINLY YES
POSSIBLY YES
CANNOT SAY
POSSIBLY NO
CERTAINLY NO
We can think of the fuzzy groups as a generalization of the regular groups, because the regular groups are boolean so a particular case of the fuzzy groups.

To represent a fuzzy models, there are several ways, being the most important one the membership function. Which declare for each element of the domain, which are on the group and which are not.

It is a boolean function that when applied to the elements of the domain, returns it’s pertinence (or not) to the group.

A visual example of membership function representing the fuzzy group “approximately zero” named μZ

μZ(x)=1/(1+x2)
Membership function
The fuzzy model allow you to define concepts in which it is not easy (or it is not possible) clearly define a point where to separate between those elements that are of the concept and those that are not. Some classic examples are those related with temperature (such as cold, hot or heat) or height (high or low).






Another example. We can consider the threshold 1,79m to consider a person tall. The membership function to model the concept is:

Membership function for height

OPERATIONS OVER FUZZY SETS:
NEGATION
Considering the membership function μA(x), we can define the negation as: μnoA(x) = N(μA(x)) where N(1)=0 and N(0)=1

But this is not enough, because the membership function is not boolean. We need to define N (named outline conditions) as N: [0,1] → [0,1]

We can also consider that the negation of the negation must be the original: N(N(a))=a for all a values [0,1]

Summing up:

The negation function is N: [0,1] → [0,1] satisfying all these conditions:

OUTLINE CONDITION: N(0)=1 i N(1)=0
MONOTONY: for all a,b on [0,1], if a≤b then N(a)≥N(b)
INVOLUTION: for all a in [0,1], N(N(a))=a
Using the height example:

Membership function for height

UNION
Now we have two sets each one of it with it’s own membership function, so if we consider μA and μB, we want to calculate the union μA∪B

As we did with the negation function N in that case we are going to use the union function S which is named t-conorm

μA ∪ B(x) = S(μA(x), μB(x))
μA ∪ B(x) is a membership function as well, so S is a function that due two values on the interval [0,1] returns another on the same interval, so:

The t-conorm function S: [0,1] x [0,1] → [0,1] satisfying the conditions:

COMMUTATIVITY: S(a,b) = S(b,a)
ASSOCIATIVITY: S(a,S(b,c)) = S(S(a,b),c)
MONOTONY: if a≤c and b≤d then S(a,b) ≤ S(c,d)
NEUTRAL ELEMENT: S(a,0)=a
where a, b, c and d are values on the interval [0,1]

Using the height example:

Membership function for height

INTERSECTION
With a similar way we can define the intersection function: μA ∩ B(x) = T(μA(x), μB(x))

This time the T function is called t-norm:

T:[0,1] x [0,1] → [0,1] satisfying the conditions:

COMMUTATIVITY: T(a,b) = T(b,a)
ASSOCIATIVITY: T(a,T(b,c)) = T(T(a,b),c)
MONOTONY: if a≤c and b≤d then T(a,b) ≤ T(c,d)
NEUTRAL ELEMENT: T(a,0)=a
where a, b, c and d are values on the interval [0,1]

Again, with the height example:

Membership function for height

BUILDING A FUZZY SYSTEM:
Any knowledge based system, should consider the group of rules to cover all the domain of the system. For that, we consider the Error (ε) and the Error Increment (Δε)

We will build the rules in a way that his premise be fulfilled only in the region that corresponds to him. To achieve this we must demand that the values of the error and of the increase of the error are in the corresponding portion of their domain. Thus, if A and B are sub-regions of the domain of ε i of Δε, then the rule:

if ε is A i Δε is B then the control variable...
Following that structure, generally:

if X1 is t1,a and X2 is t2,b and X3 is t3,c i ... i Xn is tn,z then Y is tY,o
LINGUISTIC VARIABLES:
A variable whose values are words or sentences in a natural or artificial language. Can be represented as:

<X, LX, UX, SX>
X -> Linguistic variable name
L -> Linguistic values that variable X can have
U -> Universe where the variable has values
S -> Semantic function giving sense to the linguistic values
Example:

<temperature, Ltemperature=[cold,warm,hot], Utemperature=[-50,50], Stemperature>
Where Stemperature is:

Stemperature (cold) = μcold
Stemperature (warm) = μwarm
Stemperature (hot) = μhot
Being μhot, μwarm and μcold:

Membership function for temperatureMembership function for temperature

VARIABLE SELECTION AND RULES CONSTRUCTION:
Considering what we just saw:

Linguistic terms
Membership Functions (with graphs)
Rules
We have to choose the input variables and the output variables. Then for each of these variables, it’s linguistic terms, the universe and the fuzzy sets.

If we have n input variables, X1,…, Xn, we build one rule for each tuple (t1,a, t2,b, t3,c, …, tn,z) where ti,j is a linguistic term of Xi (si ti,j ∈ LXi) a rule like:

if X1 is t1,a and X2 is t2,b and X3 is t3,c and ... and Xn is tn,z then Y is tY,o
REFERENCES:
UOC - Intel·ligència artificial

Vicenç Torra i Reventós. Què és la intel·ligència artificial

Haton, J.P.; Haton, M.C. (1993). L’intelligence Artificielle. París: Presses Universitaires de France

Luger, G.F. (1995). Computation & Intelligence. Menlo Park: MIT Press.

Vicenç Torra i Reventós. Resolució de problemes i cerca

Russell, S.; Norvig, P. (1995). Artificial Intelligence: A modern approach. Prentice-Hall.

Vicenç Torra i Reventós. Sistemes basats en el coneixement

Stefik, M. (1995). Introduction to Knowledge Systems. Morgan Kauffman.

Vicenç Torra i Reventós. Incertesa i raonament aproximat

Tutorial Point: Fuzzy Logic Systems